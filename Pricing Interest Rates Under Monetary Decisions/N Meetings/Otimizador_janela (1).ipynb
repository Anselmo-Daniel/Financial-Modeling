{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f76f2bcc-b896-44ba-9e1b-111870f4b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using Statistics\n",
    "using LsqFit\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Base.Iterators\n",
    "using DataStructures\n",
    "using JuMP\n",
    "using Ipopt\n",
    "using ForwardDiff\n",
    "using OrderedCollections\n",
    "\n",
    "#using Gurobi\n",
    "#using KNITRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbba155f-f903-4ed4-9a4d-caf82835c379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modelo (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################\n",
    "# Parametric Functions\n",
    "############################\n",
    "\n",
    "function modelo(t::Vector{T}, kappa::T, theta::T, r0::T) where {T<:Real}\n",
    "    return @. theta + (r0 - theta)*exp(-kappa*t)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "408dbe56-7791-41d8-a652-4580da20cea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "val_dist_norm (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function val_dist_norm(k::T, theta::T, r::Vector{T}, dt::T) where {T<:Real}\n",
    "    ts = T.(collect(dt:(dt + length(r) - 1)))\n",
    "    r_bar = @. theta + exp(-k*ts)*(r[1]-theta)\n",
    "    y = @. exp(k*ts)*(r - r_bar)\n",
    "\n",
    "    num = @. exp(-k*ts[2:end-1])*(y[3:end]-y[2:end-1])\n",
    "    den = @. sqrt(r[2:end-1]*dt)\n",
    "\n",
    "    dist = num ./ den\n",
    "    return dist\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02a45c61-f876-4820-8e25-2bbe885c347a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ols_model (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function ols_model(initial_guess::Vector{Float64}, taxas::Vector{Float64}; dt=1.0, \n",
    "                   lower_bounds=[0.0;0.0], upper_bounds=[Inf; Inf])\n",
    "    r0 = taxas[1]\n",
    "    t_data = collect(0:length(taxas)-1)\n",
    "\n",
    "    model_fun(t, params) = @. params[2] + (r0 - params[2])*exp(-params[1]*t)\n",
    "    fit = curve_fit(model_fun, t_data, taxas, initial_guess, lower=lower_bounds, upper=upper_bounds)\n",
    "    k, theta = fit.param\n",
    "\n",
    "    dist = val_dist_norm(k, theta, taxas, dt)\n",
    "    sigma = sqrt(sum((dist .- mean(dist)).^2)/(length(taxas)-1))\n",
    "\n",
    "    return k, theta, sigma\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb68095a-0f7d-48ed-b604-c7a4cbb348ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\u001b[1m22×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Date       \u001b[0m\u001b[1m CDI     \u001b[0m\n",
       "     │\u001b[90m Date       \u001b[0m\u001b[90m Float64 \u001b[0m\n",
       "─────┼─────────────────────\n",
       "   1 │ 2011-12-01   0.1087\n",
       "   2 │ 2011-12-02   0.1088\n",
       "   3 │ 2011-12-05   0.1089\n",
       "   4 │ 2011-12-06   0.1088\n",
       "   5 │ 2011-12-07   0.1087\n",
       "   6 │ 2011-12-08   0.1085\n",
       "   7 │ 2011-12-09   0.1083\n",
       "   8 │ 2011-12-12   0.1082\n",
       "   9 │ 2011-12-13   0.1083\n",
       "  10 │ 2011-12-14   0.1086\n",
       "  11 │ 2011-12-15   0.1087\n",
       "  12 │ 2011-12-16   0.1088\n",
       "  13 │ 2011-12-19   0.1089\n",
       "  14 │ 2011-12-20   0.109\n",
       "  15 │ 2011-12-21   0.1089\n",
       "  16 │ 2011-12-22   0.1088\n",
       "  17 │ 2011-12-23   0.1088\n",
       "  18 │ 2011-12-26   0.1085\n",
       "  19 │ 2011-12-27   0.1086\n",
       "  20 │ 2011-12-28   0.1085\n",
       "  21 │ 2011-12-29   0.1087\n",
       "  22 │ 2011-12-30   0.1087, [0.10869999999999999, 0.10880000000000001, 0.10890000000000001, 0.10880000000000001, 0.10869999999999999, 0.1085, 0.10830000000000001, 0.1082, 0.10830000000000001, 0.10859999999999999  …  0.10890000000000001, 0.109, 0.10890000000000001, 0.10880000000000001, 0.10880000000000001, 0.1085, 0.10859999999999999, 0.1085, 0.10869999999999999, 0.10869999999999999])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = CSV.read(\"selic_over_calib.csv\", DataFrame)\n",
    "taxas_calib = collect(skipmissing(df.CDI))\n",
    "\n",
    "df, taxas_calib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4231aa66-924d-468e-a521-7d5cb45bac69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20-element Vector{Float64}:\n",
       " -0.0032360230599227722\n",
       " -0.003872467522567463\n",
       " -0.0039061313583914612\n",
       " -0.004275035207354183\n",
       " -0.0043428308531708055\n",
       " -0.004074928577312253\n",
       " -0.0034368203955964884\n",
       " -0.0027316217835196012\n",
       " -0.003302829380931116\n",
       " -0.0032694105097083024\n",
       " -0.0032360230599227813\n",
       " -0.0032026669661579816\n",
       " -0.0038388354011439775\n",
       " -0.003872467522567465\n",
       " -0.0035710772091571007\n",
       " -0.004576239656860064\n",
       " -0.003336279739209112\n",
       " -0.00397355443820347\n",
       " -0.0030007627012218203\n",
       " -0.0036046187422570184"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dist_norm(0.1, 0.12, taxas_calib, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "341a03f1-195e-4800-ad04-5b5794252630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 0.4627449272360901\n",
      "theta: 0.10865651582838269\n",
      "sigma: 0.0006599155487009002\n"
     ]
    }
   ],
   "source": [
    "k, theta, sigma = ols_model([1.0,1.0], taxas_calib)\n",
    "\n",
    "println(\"k: $k\")\n",
    "println(\"theta: $theta\")\n",
    "println(\"sigma: $sigma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38a77090-d3b1-47ec-adfa-8b5e36107b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 0.050280251510732024\n",
      "b: 0.4627449272360901\n",
      "gamma: 0.23137293416678903\n"
     ]
    }
   ],
   "source": [
    "#Parametros\n",
    "a = k*theta\n",
    "b = k\n",
    "gamma = 1/2 * sqrt(b^(2) + 2*sigma^(2))\n",
    "\n",
    "println(\"a: $a\")\n",
    "println(\"b: $b\")\n",
    "println(\"gamma: $gamma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be15a154-8625-4a99-a59e-324a6259b8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PU (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################\n",
    "# Parametric Hull-White Functions\n",
    "############################\n",
    "\n",
    "function A(t::T, Tt::T, a::T, b::T, gamma::T, sigma::T) where {T<:Real}\n",
    "    return (-2*a)/(sigma^2) * log((gamma*exp(0.5*b*(Tt-t))) / (gamma*cosh(gamma*(Tt-t)) + 0.5*b*sinh(gamma*(Tt-t))))\n",
    "end\n",
    "\n",
    "function C(t::T, Tt::T, b::T, gamma::T, sigma::T) where {T<:Real}\n",
    "    return (sinh(gamma*(Tt-t))) / (gamma*cosh(gamma*(Tt-t)) + 0.5*b*sinh(gamma*(Tt-t)))\n",
    "end\n",
    "\n",
    "function B(t::T, Tt::T, M_total::T, prob::T, r_t::T, a::T, b::T, gamma::T, sigma::T) where {T<:Real}\n",
    "    return prob * exp(-M_total - A(t, Tt, a, b, gamma, sigma) - C(t, Tt, b, gamma, sigma)*r_t)\n",
    "end\n",
    "\n",
    "function PU(r_t::T, Tt::T) where {T<:Real}\n",
    "    return one(T)/((one(T)+r_t)^(Tt/252))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e4b23c0-6b0b-4790-bd93-b6df9d39728c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cria_vetor_mudancas (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function cria_vetor_mudancas(min_value::T, max_value::T) where {T<:Real}\n",
    "    step = T(0.0025)\n",
    "    num_steps = Int(round((max_value - min_value)/step)) + 1\n",
    "    return [min_value + (i-1)*step for i in 1:num_steps]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54f0a562-2b8c-4988-9f73-a684ac5f9bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7-element Vector{Float64}:\n",
       " -0.0075\n",
       " -0.004999999999999999\n",
       " -0.0024999999999999996\n",
       "  0.0\n",
       "  0.0025000000000000005\n",
       "  0.005000000000000001\n",
       "  0.0075"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cria_vetor_mudancas(-0.0075, 0.0075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c17d979-b810-4ebb-9bcc-fc798d04fffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gera_mudancas (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gera_mudancas(lista::Vector{T}) where {T<:Real}\n",
    "    num_negativ = count(x -> x < zero(T), lista)\n",
    "    num_posit = count(x -> x > zero(T), lista)\n",
    "\n",
    "    changes = String[]\n",
    "    for i in num_negativ:-1:1\n",
    "        push!(changes, \"D$(i)\")\n",
    "    end\n",
    "\n",
    "    # Só adiciona \"N\" se houver zero no vetor\n",
    "    if any(x -> x == zero(T), lista)\n",
    "        push!(changes, \"N\")\n",
    "    end\n",
    "\n",
    "    for i in 1:num_posit\n",
    "        push!(changes, \"U$(i)\")\n",
    "    end\n",
    "\n",
    "    return changes\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92ceb623-e92f-466d-a09c-773498412496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7-element Vector{String}:\n",
       " \"D3\"\n",
       " \"D2\"\n",
       " \"D1\"\n",
       " \"N\"\n",
       " \"U1\"\n",
       " \"U2\"\n",
       " \"U3\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gera_mudancas(cria_vetor_mudancas(-0.0075, 0.0075))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae77d414-2275-4d59-9612-bddc9ee6b0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cria_dicionario (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function cria_dicionario(min_value::T, max_value::T) where {T<:Real}\n",
    "    vetor_mudancas = cria_vetor_mudancas(min_value, max_value)\n",
    "    lista_mudancas = gera_mudancas(vetor_mudancas)\n",
    "    dicionario = OrderedDict{T,String}()\n",
    "    for (valor, mudanca) in zip(vetor_mudancas, lista_mudancas)\n",
    "        dicionario[valor] = mudanca\n",
    "    end\n",
    "    return dicionario\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c493396d-dea7-4699-8afb-30c825bea690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict{Float64, String} with 7 entries:\n",
       "  -0.0075 => \"D3\"\n",
       "  -0.005  => \"D2\"\n",
       "  -0.0025 => \"D1\"\n",
       "  0.0     => \"N\"\n",
       "  0.0025  => \"U1\"\n",
       "  0.005   => \"U2\"\n",
       "  0.0075  => \"U3\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cria_dicionario(-0.0075, 0.0075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd82fdc7-58c6-4bde-a7c0-178ac509d2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calcular_cenarios_distintos (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function calcular_cenarios_distintos(min_mudanca::T, max_mudanca::T, n_reunioes::Int) where {T<:Real}\n",
    "    nomes_mudancas = cria_dicionario(min_mudanca, max_mudanca)\n",
    "\n",
    "    todas_mudancas = cria_vetor_mudancas(min_mudanca, max_mudanca)\n",
    "    combinacoes = collect(product((todas_mudancas for i in 1:n_reunioes)...))\n",
    "\n",
    "    temp_cenarios = Dict{T, Vector{Vector{String}}}()\n",
    "\n",
    "    for combinacao in combinacoes\n",
    "        combo = collect(combinacao)\n",
    "        # Arredonda a soma para 5 casas decimais, por exemplo\n",
    "        mudanca_acumulada = round(sum(combo), digits=5)\n",
    "        c_nomes = [nomes_mudancas[x] for x in combo]\n",
    "\n",
    "        if !haskey(temp_cenarios, mudanca_acumulada)\n",
    "            temp_cenarios[mudanca_acumulada] = Vector{Vector{String}}()\n",
    "        end\n",
    "        push!(temp_cenarios[mudanca_acumulada], c_nomes)\n",
    "    end\n",
    "\n",
    "    sorted_keys = sort(collect(keys(temp_cenarios)))\n",
    "    cenarios = OrderedDict{T,Vector{Vector{String}}}()\n",
    "    for k in sorted_keys\n",
    "        cenarios[k] = temp_cenarios[k]\n",
    "    end\n",
    "\n",
    "    return cenarios\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2d13d83b-49a6-4b5c-949e-0a75e60724e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict{Float64, Vector{Vector{String}}} with 5 entries:\n",
       "  -0.005  => [[\"D1\", \"D1\"]]\n",
       "  -0.0025 => [[\"N\", \"D1\"], [\"D1\", \"N\"]]\n",
       "  0.0     => [[\"U1\", \"D1\"], [\"N\", \"N\"], [\"D1\", \"U1\"]]\n",
       "  0.0025  => [[\"U1\", \"N\"], [\"N\", \"U1\"]]\n",
       "  0.005   => [[\"U1\", \"U1\"]]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcular_cenarios_distintos(-0.0025, 0.0025, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a669d794-197c-4f3a-809f-025eeed47755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "caminho_para_probabilidade (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function caminho_para_probabilidade(cenario::Vector{String}, M::Matrix{T}, mudancas_descricao::Vector{String}, Q_init::Vector{T}) where {T<:Real}\n",
    "    # Esta função calcula a probabilidade de um cenário específico passo a passo.\n",
    "    # cenario: ex. [\"N\", \"U1\", \"D1\"] para 3 reuniões\n",
    "    # M: matriz de transição 3x3\n",
    "    # mudancas_descricao: ex. [\"D1\", \"N\", \"U1\"] nesta ordem\n",
    "    # Q_init: vetor distribuição inicial (row vector), ex: [0,1,0] se começamos em N.\n",
    "    #\n",
    "    # Supomos que M_ij = P(estado i -> estado j)\n",
    "    # e Q_init * M dá a próxima distribuição.\n",
    "    #\n",
    "    # Para cada passo:\n",
    "    # 1) Multiplica Q_init * M -> próxima distribuição\n",
    "    # 2) Identifica o estado desejado neste passo do cenário\n",
    "    # 3) Extrai a probabilidade correspondente e multiplica na prob total\n",
    "    # 4) Atualiza Q_init para um vetor que tenha 1 no estado escolhido.\n",
    "\n",
    "    prob_total = one(T)\n",
    "    Q_current = copy(Q_init) # distribuição corrente\n",
    "    \n",
    "    for estado_desejado in cenario\n",
    "        #println(\"Q atual: $Q_current\")\n",
    "        # Próxima distribuição\n",
    "        next_dist =  M*Q_current\n",
    "        # Índice do estado desejado\n",
    "        idx = findfirst(==(estado_desejado), mudancas_descricao)\n",
    "        if isnothing(idx)\n",
    "            error(\"Estado $(estado_desejado) não encontrado em mudancas_descricao.\")\n",
    "        end\n",
    "\n",
    "        # Extrai a probabilidade do estado desejado\n",
    "        p = next_dist[idx]\n",
    "        prob_total *= p\n",
    "\n",
    "        # Atualiza Q_current para refletir que agora estamos naquele estado\n",
    "        Q_new = zeros(T, length(mudancas_descricao))\n",
    "        Q_new[idx] = one(T) # 100% naquele estado\n",
    "        Q_current = Q_new\n",
    "    end\n",
    "\n",
    "    return prob_total\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5acd7228-dcc6-4f75-9ea8-4eb15a58781d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9-element Vector{Float64}:\n",
       " 0.5\n",
       " 0.1\n",
       " 0.4\n",
       " 0.9\n",
       " 0.1\n",
       " 0.0\n",
       " 0.25\n",
       " 0.3\n",
       " 0.45"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_test = [-0.0075, -0.0025]\n",
    "Q_prev_test = [0.0, 1.0, 0.0]\n",
    "A_prev_test = [0.5, 0.1, 0.4, 0.9, 0.1, 0.0, 0.25, 0.30, 0.45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f4bf79f-a91f-414e-bbc6-ec0cde24aaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       " 0.5  0.9  0.25\n",
       " 0.1  0.1  0.3\n",
       " 0.4  0.0  0.45"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = reshape(A_prev_test, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9723223-0555-40a7-a958-7b9d8da41392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010000000000000002"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caminho_para_probabilidade([\"U1\", \"D1\", \"N\"], M, [\"D1\", \"N\", \"U1\"], [1.0, 0.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "95d71ab9-1ca2-4bba-b20b-527118e244ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "di_model (generic function with 1 method)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function di_model(xt::Vector{T}, Q_prev::Vector{T}, t::T, Ts::T, \n",
    "                  rate_predict_t::T, num_reunioes::Int, bias::Vector{T}, \n",
    "                  a::T, b::T, gamma::T, sigma::T) where {T<:Real}\n",
    "\n",
    "    # xt é vetor com parâmetros da matriz M\n",
    "    t = t/252\n",
    "    Ts = Ts/252\n",
    "    M = reshape(xt, 3, 3)\n",
    "    #println(\"M: $M\")\n",
    "    # Q_prev é a distribuição inicial. Ex: [0,1,0] significa 100% em N\n",
    "    # Isso assume a ordem dos estados em M e mudancas_descricao é consistente.\n",
    "    # Vamos gerar as descrições\n",
    "    taxas = cria_vetor_mudancas(bias[1], bias[2])\n",
    "    mudancas_descricao = gera_mudancas(taxas)\n",
    "    # Certifique-se que a ordem em M corresponde à ordem de mudancas_descricao.\n",
    "    # Ex: Se mudancas_descricao = [\"D1\",\"N\",\"U1\"], M deve ser interpretada:\n",
    "    # linha = estado atual, coluna = próximo estado, na ordem [D1,N,U1].\n",
    "\n",
    "    # Geramos todos cenários\n",
    "    cenarios_distintos = calcular_cenarios_distintos(bias[1], bias[2], num_reunioes)\n",
    "    #println(\"Cenarios Distintos: $cenarios_distintos\")\n",
    "    \n",
    "    if length(cenarios_distintos) == 1\n",
    "        return B(t, Ts, zero(T), one(T), rate_predict_t, a, b, gamma, sigma)\n",
    "    end\n",
    "\n",
    "    c_values = collect(values(cenarios_distintos))\n",
    "    c_keys = collect(keys(cenarios_distintos))\n",
    "    soma = zero(T)\n",
    "\n",
    "    # Para cada conjunto de cenários (mesmo M_total), calculamos a soma das probabilidades\n",
    "    for i in 1:length(c_values)\n",
    "        reunioes_list = c_values[i]\n",
    "        #println(\"Reunioes: $reunioes_list\")\n",
    "        prob = zero(T)\n",
    "        # Para cada cenário possível\n",
    "        for cenario in reunioes_list\n",
    "            # cenario é algo como [\"D1\",\"N\",\"U1\"] correspondendo ao caminho D1 -> N -> U1\n",
    "            p_cenario = caminho_para_probabilidade(cenario, M, mudancas_descricao, Q_prev)\n",
    "            prob += p_cenario\n",
    "        end\n",
    "        M_total = c_keys[i]\n",
    "        soma += B(t, Ts, M_total, prob, rate_predict_t, a, b, gamma, sigma)\n",
    "    end\n",
    "\n",
    "    return soma\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7b565fd6-c7b3-4640-b83f-a56988d8afa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9-element Vector{Float64}:\n",
       " 0.5\n",
       " 0.1\n",
       " 0.4\n",
       " 0.9\n",
       " 0.1\n",
       " 0.0\n",
       " 0.25\n",
       " 0.3\n",
       " 0.45"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_test = [-0.0075, -0.0025]\n",
    "Q_prev_test = [0.0, 1.0, 0.0]\n",
    "A_prev_test = [0.5, 0.1, 0.4, 0.9, 0.1, 0.0, 0.25, 0.30, 0.45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "17e6886c-1c13-489b-9d82-19755fcfe4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0123696707146803"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "di_model(A_prev_test, Q_prev_test, 1.0, 2.0, 0.103, 2, bias_test, a, b, gamma, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3f9aa2e0-5342-4cf4-a401-d8202df65ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "objective (generic function with 1 method)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function objective(M_t::Vector{T}, bias::Vector{T}, Q_prev::Vector{T}, t::T, Ts::T, \n",
    "                   rate_pred::T, num_reunioes::Int, alpha::T, A_prev::Vector{T}, \n",
    "                   market_price::T, a::T, b::T, gamma::T, sigma::T) where {T<:Real}\n",
    "    \n",
    "    prices_model = di_model(M_t, Q_prev, t, Ts, rate_pred, num_reunioes, bias, a, b, gamma, sigma)\n",
    "    price_market = PU(market_price, Ts)\n",
    "    \n",
    "    diff_prices = price_market - prices_model\n",
    "    otimizador = 0.5 * (diff_prices^2)\n",
    "    penalizador = alpha * norm(M_t - A_prev)^2\n",
    "    return otimizador + penalizador\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f85320af-e8f5-4725-af89-aab51310a2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\u001b[1m62×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Column1    \u001b[0m\u001b[1m close   \u001b[0m\n",
       "     │\u001b[90m Date       \u001b[0m\u001b[90m Float64 \u001b[0m\n",
       "─────┼─────────────────────\n",
       "   1 │ 2012-01-02  0.1039\n",
       "   2 │ 2012-01-03  0.10375\n",
       "   3 │ 2012-01-04  0.10385\n",
       "   4 │ 2012-01-05  0.10377\n",
       "   5 │ 2012-01-06  0.10345\n",
       "   6 │ 2012-01-09  0.10332\n",
       "   7 │ 2012-01-10  0.1032\n",
       "   8 │ 2012-01-11  0.10315\n",
       "   9 │ 2012-01-12  0.1031\n",
       "  10 │ 2012-01-13  0.10295\n",
       "  11 │ 2012-01-16  0.1029\n",
       "  ⋮  │     ⋮          ⋮\n",
       "  53 │ 2012-03-19  0.0953\n",
       "  54 │ 2012-03-20  0.09527\n",
       "  55 │ 2012-03-21  0.09528\n",
       "  56 │ 2012-03-22  0.0951\n",
       "  57 │ 2012-03-23  0.0948\n",
       "  58 │ 2012-03-26  0.0952\n",
       "  59 │ 2012-03-27  0.095\n",
       "  60 │ 2012-03-28  0.0951\n",
       "  61 │ 2012-03-29  0.0948\n",
       "  62 │ 2012-03-30  0.0952\n",
       "\u001b[36m            41 rows omitted\u001b[0m, \u001b[1m63×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Date       \u001b[0m\u001b[1m CDI     \u001b[0m\n",
       "     │\u001b[90m Date       \u001b[0m\u001b[90m Float64 \u001b[0m\n",
       "─────┼─────────────────────\n",
       "   1 │ 2012-01-02   0.1089\n",
       "   2 │ 2012-01-03   0.1088\n",
       "   3 │ 2012-01-04   0.1088\n",
       "   4 │ 2012-01-05   0.1085\n",
       "   5 │ 2012-01-06   0.1086\n",
       "   6 │ 2012-01-09   0.1082\n",
       "   7 │ 2012-01-10   0.1083\n",
       "   8 │ 2012-01-11   0.1082\n",
       "   9 │ 2012-01-12   0.1081\n",
       "  10 │ 2012-01-13   0.1082\n",
       "  11 │ 2012-01-16   0.1082\n",
       "  ⋮  │     ⋮          ⋮\n",
       "  54 │ 2012-03-19   0.0948\n",
       "  55 │ 2012-03-20   0.0948\n",
       "  56 │ 2012-03-21   0.0948\n",
       "  57 │ 2012-03-22   0.0948\n",
       "  58 │ 2012-03-23   0.0952\n",
       "  59 │ 2012-03-26   0.0949\n",
       "  60 │ 2012-03-27   0.0949\n",
       "  61 │ 2012-03-28   0.0948\n",
       "  62 │ 2012-03-29   0.0948\n",
       "  63 │ 2012-03-30   0.0952\n",
       "\u001b[36m            42 rows omitted\u001b[0m)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_over = CSV.read(\"selic_over_jan_mar_2012.csv\", DataFrame)\n",
    "taxas_over = collect(skipmissing(df_over.CDI))\n",
    "\n",
    "df_market = CSV.read(\"di_2012J.csv\", DataFrame)\n",
    "taxas_market = collect(skipmissing(df_market.close))\n",
    "\n",
    "df_market, df_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a9b8d777-b89c-4492-afad-399fc9afe863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.043760093864051e-5, 3.0437600960360224e-5, 0.12267938706002919)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_test1 = [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]\n",
    "M_test2 = [-2.3033499815659325e-9, 1.0000000093924066, -7.089056696700291e-9,\n",
    "    -4.698077660731161e-9, 1.0000000099746342, -5.2765566326496385e-9, 2.3783922910256537e-8, 0.9999999862158437, -9.999766630295012e-9]\n",
    "M_gen  = [0.73, 0.0, 0.33, 0.13, 0.87, 0.33, 0.14, 0.13, 0.34] \n",
    "\n",
    "A_prev = [0.33, 0.33, 0.34, 0.33, 0.34, 0.33, 0.34, 0.33, 0.33]\n",
    "bias = [-0.0075, -0.0025]\n",
    "Q_prev = [0.0, 1.0, 0.0]\n",
    "\n",
    "t = 1.0\n",
    "Ts = 62.0\n",
    "\n",
    "objective(M_test1, bias, Q_prev, t, Ts,\n",
    "                   taxas_over[1], 2, 0.0, A_prev, \n",
    "                   taxas_market[1], a, b, gamma, sigma), objective(M_test2, bias, Q_prev, t, Ts,\n",
    "                   taxas_over[1], 2, 0.0, A_prev, \n",
    "                   taxas_market[1], a, b, gamma, sigma), objective(M_gen, bias, Q_prev, t, Ts,\n",
    "                   taxas_over[1], 2, 0.0, A_prev, \n",
    "                   taxas_market[1], a, b, gamma, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9b9c89ac-8574-418f-9673-8fa150965ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9615334375528456, 0.1039)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_pred = taxas_over[1]\n",
    "num_reunioes = 2\n",
    "alpha = 0.0\n",
    "market_price = taxas_market[1]\n",
    "PU(market_price, 100.0), market_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "042f0e91-daa0-4829-8063-afd59914bfb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "Unable to register the function :my_objective.\n\nCommon reasons for this include:\n\n * The function takes `f(x::Vector)` as input, instead of the splatted\n   `f(x...)`.\n * The function assumes `Float64` will be passed as input, it must work for any\n   generic `Real` type.\n * The function allocates temporary storage using `zeros(3)` or similar. This\n   defaults to `Float64`, so use `zeros(T, 3)` instead.\n\nAs examples, instead of:\n```julia\nmy_function(x::Vector) = sum(x.^2)\n```\nuse:\n```julia\nmy_function(x::T...) where {T<:Real} = sum(x[i]^2 for i in 1:length(x))\n```\n\nInstead of:\n```julia\nfunction my_function(x::Float64...)\n    y = zeros(length(x))\n    for i in 1:length(x)\n        y[i] = x[i]^2\n    end\n    return sum(y)\nend\n```\nuse:\n```julia\nfunction my_function(x::T...) where {T<:Real}\n    y = zeros(T, length(x))\n    for i in 1:length(x)\n        y[i] = x[i]^2\n    end\n    return sum(y)\nend\n```\n\nReview the stacktrace below for more information, but it can often be hard to\nunderstand why and where your function is failing. You can also debug this\noutside of JuMP as follows:\n```julia\nimport ForwardDiff\n\n# If the input dimension is 1\nx = 1.0\nmy_function(a) = a^2\nForwardDiff.derivative(my_function, x)\n\n# If the input dimension is more than 1\nx = [1.0, 2.0]\nmy_function(a, b) = a^2 + b^2\nForwardDiff.gradient(x -> my_function(x...), x)\n```\n",
     "output_type": "error",
     "traceback": [
      "Unable to register the function :my_objective.\n\nCommon reasons for this include:\n\n * The function takes `f(x::Vector)` as input, instead of the splatted\n   `f(x...)`.\n * The function assumes `Float64` will be passed as input, it must work for any\n   generic `Real` type.\n * The function allocates temporary storage using `zeros(3)` or similar. This\n   defaults to `Float64`, so use `zeros(T, 3)` instead.\n\nAs examples, instead of:\n```julia\nmy_function(x::Vector) = sum(x.^2)\n```\nuse:\n```julia\nmy_function(x::T...) where {T<:Real} = sum(x[i]^2 for i in 1:length(x))\n```\n\nInstead of:\n```julia\nfunction my_function(x::Float64...)\n    y = zeros(length(x))\n    for i in 1:length(x)\n        y[i] = x[i]^2\n    end\n    return sum(y)\nend\n```\nuse:\n```julia\nfunction my_function(x::T...) where {T<:Real}\n    y = zeros(T, length(x))\n    for i in 1:length(x)\n        y[i] = x[i]^2\n    end\n    return sum(y)\nend\n```\n\nReview the stacktrace below for more information, but it can often be hard to\nunderstand why and where your function is failing. You can also debug this\noutside of JuMP as follows:\n```julia\nimport ForwardDiff\n\n# If the input dimension is 1\nx = 1.0\nmy_function(a) = a^2\nForwardDiff.derivative(my_function, x)\n\n# If the input dimension is more than 1\nx = [1.0, 2.0]\nmy_function(a, b) = a^2 + b^2\nForwardDiff.gradient(x -> my_function(x...), x)\n```\n",
      "",
      "Stacktrace:",
      " [1] error(s::String)",
      "   @ Base .\\error.jl:35",
      " [2] _validate_register_assumptions(f::typeof(my_objective), name::Symbol, dimension::Int64)",
      "   @ MathOptInterface.Nonlinear C:\\Users\\danie\\.julia\\packages\\MathOptInterface\\gLl4d\\src\\Nonlinear\\operators.jl:334",
      " [3] (MathOptInterface.Nonlinear._MultivariateOperator{9})(op::Symbol, f::Function)",
      "   @ MathOptInterface.Nonlinear C:\\Users\\danie\\.julia\\packages\\MathOptInterface\\gLl4d\\src\\Nonlinear\\operators.jl:367",
      " [4] register_operator(registry::MathOptInterface.Nonlinear.OperatorRegistry, op::Symbol, nargs::Int64, f::Function)",
      "   @ MathOptInterface.Nonlinear C:\\Users\\danie\\.julia\\packages\\MathOptInterface\\gLl4d\\src\\Nonlinear\\operators.jl:420",
      " [5] register_operator",
      "   @ C:\\Users\\danie\\.julia\\packages\\MathOptInterface\\gLl4d\\src\\Nonlinear\\model.jl:299 [inlined]",
      " [6] register(model::Model, op::Symbol, dimension::Int64, f::Function; autodiff::Bool)",
      "   @ JuMP C:\\Users\\danie\\.julia\\packages\\JuMP\\i68GU\\src\\nlp.jl:806",
      " [7] top-level scope",
      "   @ In[91]:36"
     ]
    }
   ],
   "source": [
    "# Função a ser registrada\n",
    "function my_objective(x1::T, x2::T, x3::T, x4::T, x5::T, x6::T, x7::T, x8::T, x9::T) where {T<:Real}\n",
    "    # Constrói a matriz M_t do tipo T\n",
    "    M_t = reshape(T[x1, x2, x3, x4, x5, x6, x7, x8, x9], 3, 3)\n",
    "\n",
    "    # Converte parâmetros externos para tipo T\n",
    "    bias_T = T.(bias)\n",
    "    Q_prev_T = T.(Q_prev)\n",
    "    A_prev_T = T.(A_prev)\n",
    "    market_price_T = T(market_price)\n",
    "    a_T = T(a)\n",
    "    b_T = T(b)\n",
    "    gamma_T = T(gamma)\n",
    "    sigma_T = T(sigma)\n",
    "    rate_pred_T = T(rate_pred)\n",
    "    t_T = T(t)\n",
    "    Ts_T = T(Ts)\n",
    "    alpha_T = T(alpha)\n",
    "    \n",
    "    # Chama a função objective assumindo que ela é compatível com T\n",
    "    return objective(vec(M_t), bias_T, Q_prev_T, t_T, Ts_T, rate_pred_T, num_reunioes, alpha_T, A_prev_T, market_price_T, a_T, b_T, gamma_T, sigma_T)\n",
    "end\n",
    "\n",
    "model = Model(Ipopt.Optimizer)\n",
    "\n",
    "set_optimizer_attribute(model, \"print_level\", 5)\n",
    "set_optimizer_attribute(model, \"sb\", \"yes\")\n",
    "set_optimizer_attribute(model, \"max_cpu_time\", 60.0)\n",
    "\n",
    "@variable(model, M[1:3, 1:3])\n",
    "@constraint(model, [i in 1:3, j in 1:3], M[i, j] >= 0)\n",
    "@constraint(model, [i in 1:3, j in 1:3], M[i, j] <= 1)\n",
    "@constraint(model, [i in 1:3], sum(M[i,j] for j in 1:3) == 1)\n",
    "\n",
    "# Registra a função. Note que agora não passamos closure, mas sim a função pura definida acima.\n",
    "JuMP.register(model, :my_objective, 9, my_objective, autodiff=true)\n",
    "\n",
    "@NLobjective(model, Min, my_objective(M[1,1], M[1,2], M[1,3],\n",
    "                                     M[2,1], M[2,2], M[2,3],\n",
    "                                     M[3,1], M[3,2], M[3,3]))\n",
    "\n",
    "optimize!(model)\n",
    "\n",
    "println(\"Status: \", termination_status(model))\n",
    "println(\"Solution M: \", value.(M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "421e67f4-be9e-4cf0-b5eb-a85b33cf6b35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "Unable to register the function :my_objective.\n\nCommon reasons for this include:\n\n * The function takes `f(x::Vector)` as input, instead of the splatted\n   `f(x...)`.\n * The function assumes `Float64` will be passed as input, it must work for any\n   generic `Real` type.\n * The function allocates temporary storage using `zeros(3)` or similar. This\n   defaults to `Float64`, so use `zeros(T, 3)` instead.\n\nAs examples, instead of:\n```julia\nmy_function(x::Vector) = sum(x.^2)\n```\nuse:\n```julia\nmy_function(x::T...) where {T<:Real} = sum(x[i]^2 for i in 1:length(x))\n```\n\nInstead of:\n```julia\nfunction my_function(x::Float64...)\n    y = zeros(length(x))\n    for i in 1:length(x)\n        y[i] = x[i]^2\n    end\n    return sum(y)\nend\n```\nuse:\n```julia\nfunction my_function(x::T...) where {T<:Real}\n    y = zeros(T, length(x))\n    for i in 1:length(x)\n        y[i] = x[i]^2\n    end\n    return sum(y)\nend\n```\n\nReview the stacktrace below for more information, but it can often be hard to\nunderstand why and where your function is failing. You can also debug this\noutside of JuMP as follows:\n```julia\nimport ForwardDiff\n\n# If the input dimension is 1\nx = 1.0\nmy_function(a) = a^2\nForwardDiff.derivative(my_function, x)\n\n# If the input dimension is more than 1\nx = [1.0, 2.0]\nmy_function(a, b) = a^2 + b^2\nForwardDiff.gradient(x -> my_function(x...), x)\n```\n",
     "output_type": "error",
     "traceback": [
      "Unable to register the function :my_objective.\n\nCommon reasons for this include:\n\n * The function takes `f(x::Vector)` as input, instead of the splatted\n   `f(x...)`.\n * The function assumes `Float64` will be passed as input, it must work for any\n   generic `Real` type.\n * The function allocates temporary storage using `zeros(3)` or similar. This\n   defaults to `Float64`, so use `zeros(T, 3)` instead.\n\nAs examples, instead of:\n```julia\nmy_function(x::Vector) = sum(x.^2)\n```\nuse:\n```julia\nmy_function(x::T...) where {T<:Real} = sum(x[i]^2 for i in 1:length(x))\n```\n\nInstead of:\n```julia\nfunction my_function(x::Float64...)\n    y = zeros(length(x))\n    for i in 1:length(x)\n        y[i] = x[i]^2\n    end\n    return sum(y)\nend\n```\nuse:\n```julia\nfunction my_function(x::T...) where {T<:Real}\n    y = zeros(T, length(x))\n    for i in 1:length(x)\n        y[i] = x[i]^2\n    end\n    return sum(y)\nend\n```\n\nReview the stacktrace below for more information, but it can often be hard to\nunderstand why and where your function is failing. You can also debug this\noutside of JuMP as follows:\n```julia\nimport ForwardDiff\n\n# If the input dimension is 1\nx = 1.0\nmy_function(a) = a^2\nForwardDiff.derivative(my_function, x)\n\n# If the input dimension is more than 1\nx = [1.0, 2.0]\nmy_function(a, b) = a^2 + b^2\nForwardDiff.gradient(x -> my_function(x...), x)\n```\n",
      "",
      "Stacktrace:",
      " [1] error(s::String)",
      "   @ Base .\\error.jl:35",
      " [2] _validate_register_assumptions(f::var\"#23#24\", name::Symbol, dimension::Int64)",
      "   @ MathOptInterface.Nonlinear C:\\Users\\danie\\.julia\\packages\\MathOptInterface\\gLl4d\\src\\Nonlinear\\operators.jl:334",
      " [3] (MathOptInterface.Nonlinear._MultivariateOperator{9})(op::Symbol, f::Function)",
      "   @ MathOptInterface.Nonlinear C:\\Users\\danie\\.julia\\packages\\MathOptInterface\\gLl4d\\src\\Nonlinear\\operators.jl:367",
      " [4] register_operator(registry::MathOptInterface.Nonlinear.OperatorRegistry, op::Symbol, nargs::Int64, f::Function)",
      "   @ MathOptInterface.Nonlinear C:\\Users\\danie\\.julia\\packages\\MathOptInterface\\gLl4d\\src\\Nonlinear\\operators.jl:420",
      " [5] register_operator",
      "   @ C:\\Users\\danie\\.julia\\packages\\MathOptInterface\\gLl4d\\src\\Nonlinear\\model.jl:299 [inlined]",
      " [6] register(model::Model, op::Symbol, dimension::Int64, f::Function; autodiff::Bool)",
      "   @ JuMP C:\\Users\\danie\\.julia\\packages\\JuMP\\i68GU\\src\\nlp.jl:806",
      " [7] top-level scope",
      "   @ In[29]:53"
     ]
    }
   ],
   "source": [
    "############################\n",
    "# Final Objective Callable\n",
    "############################\n",
    "\n",
    "function my_objective(x::T...) where {T<:Real}\n",
    "    M_array = Vector{T}(undef, length(x))\n",
    "    @inbounds for i in 1:length(x)\n",
    "        M_array[i] = x[i]\n",
    "    end\n",
    "\n",
    "    # Convert global data to type T\n",
    "    bias_T = T.(bias)\n",
    "    Q_prev_T = T.(Q_prev)\n",
    "    A_prev_T = T.(A_prev)\n",
    "    market_price_T = T(market_price)\n",
    "    a_T = T(a)\n",
    "    b_T = T(b)\n",
    "    gamma_T = T(gamma)\n",
    "    sigma_T = T(sigma)\n",
    "    rate_pred_T = T(rate_pred)\n",
    "    t_T = T(t)\n",
    "    Ts_T = T(Ts)\n",
    "    alpha_T = T(alpha)\n",
    "\n",
    "    return objective(M_array, bias_T, Q_prev_T, t_T, Ts_T, rate_pred_T, num_reunioes, alpha_T, A_prev_T, market_price_T, a_T, b_T, gamma_T, sigma_T)\n",
    "end\n",
    "\n",
    "############################\n",
    "# JuMP Model\n",
    "############################\n",
    "\n",
    "model = Model(Ipopt.Optimizer)\n",
    "\n",
    "# Enable verbose output\n",
    "set_optimizer_attribute(model, \"print_level\", 5)  # Maximum verbosity\n",
    "set_optimizer_attribute(model, \"sb\", \"yes\")        # Short banner\n",
    "# Optional: Redirect output to a file\n",
    "# set_optimizer_attribute(model, \"output_file\", \"ipopt_output.log\")\n",
    "\n",
    "# Optional: Set maximum CPU time (in seconds) to prevent indefinite running\n",
    "set_optimizer_attribute(model, \"max_cpu_time\", 60.0)  # 1 minute\n",
    "\n",
    "# Optional: Set maximum number of iterations\n",
    "#set_optimizer_attribute(model, \"max_iter\", 1000)\n",
    "\n",
    "@variable(model, M[1:3, 1:3])\n",
    "# Add constraints to ensure each entry of M is between 0 and 1\n",
    "@constraint(model, [i in 1:3, j in 1:3], M[i, j] >= 0)\n",
    "@constraint(model, [i in 1:3, j in 1:3], M[i, j] <= 1)\n",
    "@constraint(model, [i in 1:3], sum(M[i,j] for j in 1:3) == 1)\n",
    "\n",
    "# Registering the function\n",
    "JuMP.register(model, :my_objective, 9, (x1,x2,x3,x4,x5,x6,x7,x8,x9)->my_objective(x1,x2,x3,x4,x5,x6,x7,x8,x9), autodiff=true)\n",
    "\n",
    "@NLobjective(model, Min, my_objective(M[1,1], M[1,2], M[1,3],\n",
    "                                     M[2,1], M[2,2], M[2,3],\n",
    "                                     M[3,1], M[3,2], M[3,3]))\n",
    "\n",
    "optimize!(model)\n",
    "\n",
    "println(\"Status: \", termination_status(model))\n",
    "println(\"Solution M: \", value.(M))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
